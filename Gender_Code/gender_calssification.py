# -*- coding: utf-8 -*-
"""gender calssification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TF3v4tWfMmWAihBrU32OOhUIZCKPrVNK
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, ConcatDataset
import os
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import cv2

# read the input image
img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01/Gender01/train/male/JPCLN001.png')

# image properties
print("Type:",type(img))
print("Shape of Image:", img.shape)
print('Total Number of pixels:', img.size)
print("Image data type:", img.dtype)

# print("Pixel Values:\n", img)
print("Dimension:", img.ndim)

gender_data_dirs = [
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01/Gender01',
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01_Index/Gender01_Index',
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01_RGB/Gender01_RGB'
]

# Define transformations
gender_data_transforms = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),  # Increased rotation range
    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Random cropping
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
    transforms.RandomErasing(p=0.5),  # Randomly erases part of the image
    transforms.ToTensor(),
])


# Function to load datasets
def gender_load_dataset(gender_data_dir):
    return {
        'train': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'train'),
            transform=gender_data_transforms
        ),
        'test': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'test'),
            transform=transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
        )
    }

# Initialize empty lists for train and test datasets
gender_train_datasets = []
gender_test_datasets = []

# Load datasets from each directory
for dir in gender_data_dirs:
    datasets_dict = gender_load_dataset(dir)
    gender_train_datasets.append(datasets_dict['train'])
    gender_test_datasets.append(datasets_dict['test'])

# Concatenate datasets
combined_gender_train_dataset = ConcatDataset(gender_train_datasets)
combined_gender_test_dataset = ConcatDataset(gender_test_datasets)

# Create DataLoaders
gender_dataloaders = {
    'train': DataLoader(combined_gender_train_dataset, batch_size=32, shuffle=True, num_workers=2),
    'test': DataLoader(combined_gender_test_dataset, batch_size=32, shuffle=False, num_workers=2),
}

gender_dataset_sizes = {x: len(gender_dataloaders[x].dataset) for x in ['train', 'test']}
gender_dataset_sizes

class_names = gender_train_datasets[0].classes
class_names

model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))

model = model.to(device)

criterion = nn.CrossEntropyLoss()

optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Increased learning rate
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)

# Training loop
num_epochs = 50
total_step = len(gender_dataloaders['train'])

for epoch in range(num_epochs):
    model.train()

    for i, (inputs, labels) in enumerate(gender_dataloaders['train']):
        inputs, labels = inputs.to(device), labels.to(device)

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i + 1) % 15 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}')

    scheduler.step()

def resnet18_test():
    model.eval()
    correct = 0
    total = 0


    for images, labels in gender_dataloaders['test']:
        images = images.to(device)
        labels = labels.to(device)

        test_output = model(images)
        pred_y = torch.max(test_output, 1)[1].data.squeeze()

        total += labels.size(0)
        correct += (pred_y == labels).sum().item()

    accuracy = 100 * correct / total
    print('Test Accuracy of the model on the test images: {:.2f}%'.format(accuracy))

resnet18_test()

import random

def imshow(inp, title=None, figsize=(4, 4)):
    """Display the image with a smaller size."""
    inp = inp.numpy().transpose((1, 2, 0))
    plt.figure(figsize=figsize)  # Set the figure size to make the photo smaller
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.axis('off')  # Hide the axes for better visualization
    plt.pause(0.001)  # Pause to allow the plot to be updated

# Get a batch of images and labels from the test DataLoader
inputs, classes = next(iter(gender_dataloaders['test']))

# Move inputs to the appropriate device
inputs = inputs.to(device)

# Get model predictions
outputs = model(inputs)
_, preds = torch.max(outputs, 1)

# Randomly select a few images to display
num_images = 5  # Number of images to display
selected_indices = random.sample(range(inputs.size(0)), num_images)

# Display the randomly selected images
for j in selected_indices:
    imshow(inputs.cpu().data[j], title='Predicted: {} Actual: {}'.format(class_names[preds[j]], class_names[classes[j]]))

# -*- coding: utf-8 -*-
"""gender_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TF3v4tWfMmWAihBrU32OOhUIZCKPrVNK
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, ConcatDataset
import os
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import matplotlib.pyplot as plt
from transformers import SwinForImageClassification

from google.colab import drive
drive.mount('/content/drive')

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import cv2

# Read the input image
img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01_RGB/Gender01_RGB/train/male/JPCLN001.png')

# Image properties
print("Type:", type(img))
print("Shape of Image:", img.shape)
print('Total Number of pixels:', img.size)
print("Image data type:", img.dtype)
print("Dimension:", img.ndim)

gender_data_dirs = [
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01/Gender01',
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01_Index/Gender01_Index',
    '/content/drive/MyDrive/Colab Notebooks/Gender_Classification/Gender01_RGB/Gender01_RGB'
]

gender_data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to 224x224 to match Swin-Tiny input requirements
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Ensure that the final output size is 224x224
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
    transforms.ToTensor(),  # Convert PIL Image to Tensor
    transforms.RandomErasing(p=0.5),  # Apply RandomErasing on Tensor
])

def gender_load_dataset(gender_data_dir):
    return {
        'train': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'train'),
            transform=gender_data_transforms
        ),
        'test': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'test'),
            transform=transforms.Compose([
                transforms.Resize((224, 224)),  # Ensure test images are also resized to 224x224
                transforms.ToTensor(),
            ])
        )
    }

# Initialize empty lists for train and test datasets
gender_train_datasets = []
gender_test_datasets = []

# Load datasets from each directory
for dir in gender_data_dirs:
    datasets_dict = gender_load_dataset(dir)
    gender_train_datasets.append(datasets_dict['train'])
    gender_test_datasets.append(datasets_dict['test'])

# Concatenate datasets
combined_gender_train_dataset = ConcatDataset(gender_train_datasets)
combined_gender_test_dataset = ConcatDataset(gender_test_datasets)

# Create DataLoaders
gender_dataloaders = {
    'train': DataLoader(combined_gender_train_dataset, batch_size=32, shuffle=True, num_workers=2),
    'test': DataLoader(combined_gender_test_dataset, batch_size=32, shuffle=False, num_workers=2),
}

# Get class names
class_names = gender_train_datasets[0].classes

# Define ResNet-18
def create_resnet18():
    model = models.resnet18(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_ftrs, len(class_names))
    )
    return model.to(device)

# Define ResNet-50
def create_resnet50():
    model = models.resnet50(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_ftrs, len(class_names))
    )
    return model.to(device)


# Training function
def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=50):
    train_losses = []
    test_losses = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in dataloaders['train']:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)


        scheduler.step()
        epoch_loss = running_loss / len(dataloaders['train'].dataset)
        train_losses.append(epoch_loss)

        # Evaluation
        model.eval()
        test_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in dataloaders['test']:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                test_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                correct += torch.sum(preds == labels)
                total += labels.size(0)

        epoch_test_loss = test_loss / len(dataloaders['test'].dataset)
        test_losses.append(epoch_test_loss)

        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Test Loss: {epoch_test_loss:.4f}, Accuracy: {correct / total:.4f}')

    return train_losses, test_losses

# Confusion matrix function
def plot_confusion_matrix(model, dataloader, model_name):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            preds = torch.max(outputs, 1)[1]
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

# Training and Evaluation
# Set common hyperparameters
criterion = nn.CrossEntropyLoss()
num_epochs = 50

# Train ResNet-18
resnet18 = create_resnet18()
optimizer_resnet18 = optim.Adam(resnet18.parameters(), lr=0.0001, weight_decay=1e-4)
scheduler_resnet18 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_resnet18, T_max=10, eta_min=1e-6)
train_losses_resnet18, test_losses_resnet18 = train_model(resnet18, gender_dataloaders, criterion, optimizer_resnet18, scheduler_resnet18, num_epochs)

# Train ResNet-50
resnet50 = create_resnet50()
optimizer_resnet50 = optim.Adam(resnet50.parameters(), lr=0.0001, weight_decay=1e-4)
scheduler_resnet50 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_resnet50, T_max=10, eta_min=1e-6)
train_losses_resnet50, test_losses_resnet50 = train_model(resnet50, gender_dataloaders, criterion, optimizer_resnet50, scheduler_resnet50, num_epochs)

from transformers import SwinForImageClassification, AutoFeatureExtractor

# Initialize the feature extractor for Swin
extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")

# Define transformation compatible with Swin
swin_data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to 224x224 to match Swin-Tiny input requirements
    transforms.ToTensor(),  # Convert PIL Image to Tensor
])

# Function to load the dataset with Swin's transformations
def swin_load_dataset(gender_data_dir):
    return {
        'train': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'train'),
            transform=swin_data_transforms
        ),
        'test': datasets.ImageFolder(
            os.path.join(gender_data_dir, 'test'),
            transform=swin_data_transforms
        )
    }

# Initialize empty lists for train and test datasets
swin_train_datasets = []
swin_test_datasets = []

# Load datasets from each directory
for dir in gender_data_dirs:
    datasets_dict = swin_load_dataset(dir)
    swin_train_datasets.append(datasets_dict['train'])
    swin_test_datasets.append(datasets_dict['test'])

# Concatenate datasets
combined_swin_train_dataset = ConcatDataset(swin_train_datasets)
combined_swin_test_dataset = ConcatDataset(swin_test_datasets)

# Create DataLoaders
swin_dataloaders = {
    'train': DataLoader(combined_swin_train_dataset, batch_size=32, shuffle=True, num_workers=2),
    'test': DataLoader(combined_swin_test_dataset, batch_size=32, shuffle=False, num_workers=2),
}

# Load Swin-Tiny model for image classification
def create_swin_tiny():
    model = SwinForImageClassification.from_pretrained(
        "microsoft/swin-tiny-patch4-window7-224",
        num_labels=len(class_names),  # Set the number of output classes
        ignore_mismatched_sizes=True  # Ignore size mismatches for the classifier layer
    )
    return model.to(device)

# Swin-Tiny training function
def train_swin_tiny(model, dataloaders, criterion, optimizer, scheduler, num_epochs=50):
    train_losses = []
    test_losses = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in dataloaders['train']:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs).logits
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        scheduler.step()
        epoch_loss = running_loss / len(dataloaders['train'].dataset)
        train_losses.append(epoch_loss)

        # Evaluation
        model.eval()
        test_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in dataloaders['test']:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs).logits
                loss = criterion(outputs, labels)

                test_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                correct += torch.sum(preds == labels)
                total += labels.size(0)

        epoch_test_loss = test_loss / len(dataloaders['test'].dataset)
        test_losses.append(epoch_test_loss)

        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Test Loss: {epoch_test_loss:.4f}, Accuracy: {correct / total:.4f}')

    return train_losses, test_losses

# Train Swin-Tiny
swin_tiny = create_swin_tiny()
optimizer_swin_tiny = optim.Adam(swin_tiny.parameters(), lr=0.0001, weight_decay=1e-4)
scheduler_swin_tiny = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_swin_tiny, T_max=10, eta_min=1e-6)
train_losses_swin_tiny, test_losses_swin_tiny = train_swin_tiny(swin_tiny, swin_dataloaders, criterion, optimizer_swin_tiny, scheduler_swin_tiny, num_epochs)

def plot_swin_confusion_matrix(model, dataloader, model_name):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)

            # Extract logits from SwinImageClassifierOutput
            if isinstance(outputs, dict):
                outputs = outputs['logits']
            elif isinstance(outputs, (tuple, list)):
                outputs = outputs[0]
            else:
                outputs = outputs.logits

            preds = torch.max(outputs, 1)[1]  # Get the index of the max logit
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

# Plot loss comparison
def plot_loss_comparison(train_loss_resnet18, test_loss_resnet18, train_loss_resnet50, test_loss_resnet50, train_loss_swin_tiny, test_loss_swin_tiny):
    plt.figure(figsize=(10, 5))
    plt.plot(train_loss_resnet18, label='ResNet-18 Train Loss')
    plt.plot(test_loss_resnet18, label='ResNet-18 Test Loss')
    plt.plot(train_loss_resnet50, label='ResNet-50 Train Loss')
    plt.plot(test_loss_resnet50, label='ResNet-50 Test Loss')
    plt.plot(train_loss_swin_tiny, label='Swin-Tiny Train Loss')
    plt.plot(test_loss_swin_tiny, label='Swin-Tiny Test Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Train and Test Loss Comparison')
    plt.legend()
    plt.show()


plot_loss_comparison(train_losses_resnet18, test_losses_resnet18, train_losses_resnet50, test_losses_resnet50, train_losses_swin_tiny, test_losses_swin_tiny)


# Plot confusion matrices for all models
plot_confusion_matrix(resnet18, gender_dataloaders['test'], 'ResNet-18')
plot_confusion_matrix(resnet50, gender_dataloaders['test'], 'ResNet-50')
plot_swin_confusion_matrix(swin_tiny, swin_dataloaders['test'], 'Swin-Tiny')

# Visualization of Predictions
import random

def imshow(inp, title=None, figsize=(4, 4)):
    """Display the image with a smaller size."""
    inp = inp.numpy().transpose((1, 2, 0))
    plt.figure(figsize=figsize)  # Set the figure size to make the photo smaller
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.axis('off')  # Hide the axes for better visualization
    plt.pause(0.001)  # Pause to allow the plot to be updated

# Get a batch of images and labels from the test DataLoader
inputs, classes = next(iter(gender_dataloaders['test']))

# Move inputs to the appropriate device
inputs = inputs.to(device)

# Get model predictions
outputs = resnet18(inputs)  # You can choose any trained model here
_, preds = torch.max(outputs, 1)

# Randomly select a few images to display
num_images = 5  # Number of images to display
selected_indices = random.sample(range(inputs.size(0)), num_images)

# Display the randomly selected images
for j in selected_indices:
    imshow(inputs.cpu().data[j], title='Predicted: {} Actual: {}'.format(class_names[preds[j]], class_names[classes[j]]))

